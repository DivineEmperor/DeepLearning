{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# extract labels (number IDs) and remove from data\n",
    "data.describe()\n",
    "labels = data['label']\n",
    "data   = data.drop('label',axis=1)\n",
    "data.describe()\n",
    "data = data.values\n",
    "dataNorm = data / np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNdigit(nn.Module):\n",
    "  def __init__(self,nUnits,nLayers):\n",
    "    super().__init__()\n",
    "\n",
    "    # create dictionary to store the layers\n",
    "    self.layers = nn.ModuleDict()\n",
    "    self.nLayers = nLayers#nLayers#\n",
    "\n",
    "    ### input layer\n",
    "    self.layers['input'] = nn.Linear(784,nUnits)\n",
    "\n",
    "    ### hidden layers\n",
    "    for i in range(nLayers):\n",
    "      self.layers[f'hidden{i}'] = nn.Linear(nUnits,nUnits)\n",
    "\n",
    "    ### output layer\n",
    "    self.layers['output'] = nn.Linear(nUnits,10)\n",
    "\n",
    "\n",
    "  # forward pass\n",
    "  def forward(self,x):\n",
    "    # input layer (note: the code in the video omits the relu after this layer)\n",
    "    x = F.relu( self.layers['input'](x) )\n",
    "\n",
    "    # hidden layers\n",
    "    for i in range(self.nLayers):\n",
    "      if i < self.nLayers:\n",
    "        x = F.relu( self.layers[f'hidden{i}'](x) )\n",
    "\n",
    "    # return output layer\n",
    "    x = self.layers['output'](x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels.values ).long() # long = int64\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTheMNISTNet(units,layers):\n",
    "\n",
    "  \n",
    "      # NEW HERE: log-softmax the output, because I'm using NLLLoss instead of CrossEntropyLoss\n",
    "  \n",
    "  # create the model instance\n",
    "  net = ANNdigit(nUnits=units,nLayers=layers)\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(net.parameters(),lr=.01)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Loss:\n",
      "tensor(2.4437, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test the model with one batch\n",
    "net,lossfun,optimizer = createTheMNISTNet(1,50)\n",
    "\n",
    "X,y = next(iter(train_loader))\n",
    "yHat = net(X)\n",
    "\n",
    "# values are log-probability of each number (0-9)\n",
    "# print(torch.exp(yHat))\n",
    "\n",
    "# now let's compute the loss\n",
    "loss = lossfun(yHat,y)\n",
    "print(' ')\n",
    "print('Loss:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2trainTheModel(units,layers):\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 60\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTNet(units=units,layers=layers)\n",
    "\n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return testAcc,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6178, 0.4992, 0.3745, 0.3300, 0.3012, 0.2778, 0.2589, 0.2416, 0.2261,\n",
      "        0.2129, 0.2005, 0.1889, 0.1786, 0.1690, 0.1606, 0.1527, 0.1454, 0.1394,\n",
      "        0.1330, 0.1280, 0.1224, 0.1172, 0.1134, 0.1094, 0.1050, 0.1019, 0.0978,\n",
      "        0.0945, 0.0915, 0.0878, 0.0854, 0.0830, 0.0800, 0.0772, 0.0747, 0.0725,\n",
      "        0.0706, 0.0679, 0.0659, 0.0639, 0.0617, 0.0599, 0.0581, 0.0559, 0.0545,\n",
      "        0.0528, 0.0514, 0.0496, 0.0481, 0.0468, 0.0453, 0.0436, 0.0423, 0.0410,\n",
      "        0.0400, 0.0387, 0.0372, 0.0363, 0.0349, 0.0342])\n",
      "tensor([1.5339, 0.4810, 0.3678, 0.3229, 0.2935, 0.2685, 0.2482, 0.2304, 0.2130,\n",
      "        0.1989, 0.1855, 0.1743, 0.1639, 0.1550, 0.1464, 0.1385, 0.1314, 0.1252,\n",
      "        0.1186, 0.1134, 0.1081, 0.1036, 0.0984, 0.0940, 0.0899, 0.0859, 0.0825,\n",
      "        0.0790, 0.0751, 0.0721, 0.0694, 0.0665, 0.0640, 0.0615, 0.0589, 0.0563,\n",
      "        0.0544, 0.0521, 0.0502, 0.0481, 0.0464, 0.0446, 0.0429, 0.0411, 0.0396,\n",
      "        0.0379, 0.0366, 0.0350, 0.0335, 0.0321, 0.0312, 0.0299, 0.0287, 0.0275,\n",
      "        0.0266, 0.0254, 0.0243, 0.0233, 0.0226, 0.0218])\n",
      "tensor([1.3988, 0.4389, 0.3425, 0.3012, 0.2734, 0.2505, 0.2301, 0.2124, 0.1972,\n",
      "        0.1835, 0.1717, 0.1607, 0.1505, 0.1420, 0.1337, 0.1259, 0.1191, 0.1121,\n",
      "        0.1064, 0.1010, 0.0955, 0.0909, 0.0861, 0.0819, 0.0779, 0.0744, 0.0709,\n",
      "        0.0673, 0.0646, 0.0614, 0.0586, 0.0557, 0.0532, 0.0512, 0.0483, 0.0464,\n",
      "        0.0446, 0.0425, 0.0405, 0.0388, 0.0371, 0.0355, 0.0338, 0.0325, 0.0310,\n",
      "        0.0297, 0.0283, 0.0270, 0.0261, 0.0245, 0.0238, 0.0228, 0.0218, 0.0208,\n",
      "        0.0202, 0.0192, 0.0184, 0.0176, 0.0167, 0.0162])\n",
      "tensor([1.4742, 0.4616, 0.3516, 0.3083, 0.2792, 0.2557, 0.2352, 0.2176, 0.2016,\n",
      "        0.1876, 0.1752, 0.1634, 0.1531, 0.1434, 0.1356, 0.1274, 0.1202, 0.1139,\n",
      "        0.1076, 0.1023, 0.0975, 0.0921, 0.0878, 0.0836, 0.0796, 0.0759, 0.0725,\n",
      "        0.0689, 0.0659, 0.0632, 0.0599, 0.0574, 0.0549, 0.0524, 0.0498, 0.0480,\n",
      "        0.0455, 0.0437, 0.0417, 0.0395, 0.0379, 0.0363, 0.0350, 0.0333, 0.0318,\n",
      "        0.0305, 0.0292, 0.0280, 0.0266, 0.0256, 0.0245, 0.0233, 0.0226, 0.0215,\n",
      "        0.0208, 0.0196, 0.0191, 0.0182, 0.0173, 0.0167])\n",
      "tensor([1.4825, 0.4670, 0.3517, 0.3090, 0.2793, 0.2562, 0.2357, 0.2175, 0.2016,\n",
      "        0.1864, 0.1736, 0.1618, 0.1508, 0.1410, 0.1328, 0.1247, 0.1174, 0.1108,\n",
      "        0.1041, 0.0986, 0.0934, 0.0882, 0.0836, 0.0794, 0.0753, 0.0715, 0.0679,\n",
      "        0.0648, 0.0616, 0.0585, 0.0557, 0.0532, 0.0505, 0.0483, 0.0455, 0.0438,\n",
      "        0.0416, 0.0395, 0.0376, 0.0361, 0.0344, 0.0326, 0.0312, 0.0298, 0.0283,\n",
      "        0.0271, 0.0256, 0.0246, 0.0235, 0.0224, 0.0214, 0.0203, 0.0193, 0.0186,\n",
      "        0.0176, 0.0169, 0.0162, 0.0156, 0.0148, 0.0141])\n",
      "tensor([2.1879, 0.8741, 0.4621, 0.3662, 0.3177, 0.2816, 0.2531, 0.2290, 0.2082,\n",
      "        0.1915, 0.1773, 0.1644, 0.1545, 0.1446, 0.1356, 0.1286, 0.1214, 0.1145,\n",
      "        0.1085, 0.1031, 0.0977, 0.0930, 0.0884, 0.0843, 0.0797, 0.0760, 0.0729,\n",
      "        0.0683, 0.0652, 0.0622, 0.0593, 0.0566, 0.0538, 0.0512, 0.0488, 0.0467,\n",
      "        0.0434, 0.0415, 0.0403, 0.0384, 0.0366, 0.0341, 0.0330, 0.0312, 0.0300,\n",
      "        0.0282, 0.0263, 0.0251, 0.0244, 0.0223, 0.0212, 0.0196, 0.0193, 0.0179,\n",
      "        0.0173, 0.0162, 0.0150, 0.0140, 0.0130, 0.0129])\n",
      "tensor([2.0865, 0.6735, 0.3971, 0.3348, 0.2952, 0.2628, 0.2345, 0.2106, 0.1902,\n",
      "        0.1722, 0.1584, 0.1456, 0.1344, 0.1245, 0.1156, 0.1076, 0.1007, 0.0937,\n",
      "        0.0873, 0.0815, 0.0771, 0.0719, 0.0677, 0.0633, 0.0594, 0.0557, 0.0521,\n",
      "        0.0495, 0.0463, 0.0428, 0.0412, 0.0381, 0.0359, 0.0335, 0.0310, 0.0296,\n",
      "        0.0271, 0.0259, 0.0239, 0.0225, 0.0213, 0.0195, 0.0183, 0.0168, 0.0159,\n",
      "        0.0148, 0.0136, 0.0128, 0.0117, 0.0111, 0.0102, 0.0097, 0.0091, 0.0085,\n",
      "        0.0079, 0.0072, 0.0069, 0.0064, 0.0059, 0.0055])\n",
      "tensor([2.0167, 0.6428, 0.3999, 0.3296, 0.2884, 0.2559, 0.2280, 0.2047, 0.1847,\n",
      "        0.1671, 0.1523, 0.1387, 0.1280, 0.1181, 0.1088, 0.1007, 0.0932, 0.0863,\n",
      "        0.0807, 0.0745, 0.0697, 0.0649, 0.0605, 0.0564, 0.0528, 0.0495, 0.0455,\n",
      "        0.0431, 0.0393, 0.0374, 0.0343, 0.0316, 0.0293, 0.0274, 0.0249, 0.0236,\n",
      "        0.0222, 0.0199, 0.0187, 0.0170, 0.0158, 0.0145, 0.0134, 0.0122, 0.0114,\n",
      "        0.0106, 0.0098, 0.0091, 0.0083, 0.0076, 0.0071, 0.0067, 0.0064, 0.0057,\n",
      "        0.0054, 0.0051, 0.0048, 0.0044, 0.0042, 0.0040])\n",
      "tensor([2.0091, 0.6139, 0.3930, 0.3293, 0.2849, 0.2500, 0.2211, 0.1972, 0.1767,\n",
      "        0.1601, 0.1462, 0.1329, 0.1230, 0.1127, 0.1032, 0.0959, 0.0894, 0.0826,\n",
      "        0.0767, 0.0709, 0.0663, 0.0617, 0.0574, 0.0533, 0.0496, 0.0465, 0.0432,\n",
      "        0.0398, 0.0372, 0.0342, 0.0319, 0.0302, 0.0274, 0.0254, 0.0236, 0.0220,\n",
      "        0.0199, 0.0185, 0.0174, 0.0156, 0.0147, 0.0133, 0.0126, 0.0115, 0.0105,\n",
      "        0.0095, 0.0089, 0.0082, 0.0076, 0.0070, 0.0065, 0.0061, 0.0056, 0.0053,\n",
      "        0.0050, 0.0046, 0.0045, 0.0043, 0.0039, 0.0038])\n",
      "tensor([1.9365, 0.6045, 0.3950, 0.3295, 0.2848, 0.2504, 0.2205, 0.1959, 0.1740,\n",
      "        0.1560, 0.1416, 0.1278, 0.1172, 0.1071, 0.0985, 0.0908, 0.0834, 0.0777,\n",
      "        0.0713, 0.0660, 0.0612, 0.0572, 0.0524, 0.0486, 0.0457, 0.0419, 0.0387,\n",
      "        0.0359, 0.0327, 0.0305, 0.0280, 0.0260, 0.0239, 0.0214, 0.0199, 0.0183,\n",
      "        0.0166, 0.0152, 0.0141, 0.0129, 0.0121, 0.0109, 0.0099, 0.0093, 0.0086,\n",
      "        0.0078, 0.0073, 0.0068, 0.0062, 0.0057, 0.0054, 0.0050, 0.0048, 0.0044,\n",
      "        0.0041, 0.0039, 0.0037, 0.0034, 0.0032, 0.0030])\n",
      "tensor([2.2980, 2.1324, 1.0840, 0.6099, 0.4483, 0.3477, 0.2794, 0.2337, 0.2010,\n",
      "        0.1775, 0.1589, 0.1431, 0.1320, 0.1213, 0.1135, 0.1049, 0.0986, 0.0919,\n",
      "        0.0870, 0.0812, 0.0763, 0.0718, 0.0690, 0.0643, 0.0613, 0.0577, 0.0544,\n",
      "        0.0510, 0.0493, 0.0452, 0.0434, 0.0416, 0.0389, 0.0366, 0.0340, 0.0309,\n",
      "        0.0309, 0.0290, 0.0273, 0.0259, 0.0232, 0.0242, 0.0216, 0.0196, 0.0180,\n",
      "        0.0171, 0.0153, 0.0169, 0.0127, 0.0134, 0.0122, 0.0109, 0.0096, 0.0088,\n",
      "        0.0081, 0.0075, 0.0078, 0.0072, 0.0087, 0.0076])\n",
      "tensor([2.2962e+00, 2.0119e+00, 7.4636e-01, 4.2439e-01, 3.4179e-01, 2.8548e-01,\n",
      "        2.4246e-01, 2.0729e-01, 1.7898e-01, 1.5699e-01, 1.3994e-01, 1.2530e-01,\n",
      "        1.1281e-01, 1.0291e-01, 9.4340e-02, 8.5794e-02, 7.9486e-02, 7.3183e-02,\n",
      "        6.6165e-02, 6.2132e-02, 5.6945e-02, 5.1695e-02, 4.7501e-02, 4.4136e-02,\n",
      "        4.0640e-02, 3.7443e-02, 3.3017e-02, 3.1289e-02, 2.8230e-02, 2.4745e-02,\n",
      "        2.3741e-02, 2.1634e-02, 1.7846e-02, 1.6894e-02, 1.5238e-02, 1.3771e-02,\n",
      "        1.1713e-02, 1.1505e-02, 9.2631e-03, 9.2422e-03, 7.4945e-03, 6.3845e-03,\n",
      "        5.7641e-03, 5.3760e-03, 4.7236e-03, 4.3505e-03, 5.4040e-03, 3.7630e-03,\n",
      "        3.2778e-03, 2.8854e-03, 2.6700e-03, 2.4106e-03, 2.1570e-03, 1.9866e-03,\n",
      "        2.0623e-03, 1.8071e-03, 1.6525e-03, 1.5234e-03, 1.3594e-03, 1.3249e-03])\n",
      "tensor([2.2928e+00, 1.8143e+00, 6.0464e-01, 4.1526e-01, 3.1870e-01, 2.5725e-01,\n",
      "        2.1637e-01, 1.8556e-01, 1.6143e-01, 1.4320e-01, 1.2765e-01, 1.1421e-01,\n",
      "        1.0430e-01, 9.3824e-02, 8.3916e-02, 7.6258e-02, 6.8892e-02, 6.2237e-02,\n",
      "        5.6576e-02, 5.0650e-02, 4.5930e-02, 4.2845e-02, 3.7258e-02, 3.3097e-02,\n",
      "        2.9420e-02, 2.6724e-02, 2.3833e-02, 2.1163e-02, 1.8674e-02, 1.6352e-02,\n",
      "        1.4290e-02, 1.2208e-02, 1.0775e-02, 9.3860e-03, 8.1773e-03, 7.1509e-03,\n",
      "        5.9389e-03, 5.1812e-03, 4.4725e-03, 4.0089e-03, 3.4673e-03, 3.0246e-03,\n",
      "        2.8693e-03, 2.7140e-03, 2.3421e-03, 1.9324e-03, 1.8537e-03, 1.6654e-03,\n",
      "        1.5123e-03, 1.4217e-03, 1.3190e-03, 1.2460e-03, 1.1921e-03, 1.1062e-03,\n",
      "        1.0489e-03, 9.9859e-04, 9.5186e-04, 9.0493e-04, 8.6461e-04, 8.2767e-04])\n",
      "tensor([2.2905e+00, 1.6924e+00, 5.6092e-01, 3.9417e-01, 3.1687e-01, 2.6554e-01,\n",
      "        2.2505e-01, 1.9170e-01, 1.6749e-01, 1.4647e-01, 1.3022e-01, 1.1637e-01,\n",
      "        1.0443e-01, 9.3913e-02, 8.4959e-02, 7.7316e-02, 6.9323e-02, 6.3012e-02,\n",
      "        5.7593e-02, 5.1926e-02, 4.5451e-02, 4.1371e-02, 3.8050e-02, 3.3336e-02,\n",
      "        3.0038e-02, 2.7081e-02, 2.4054e-02, 2.0784e-02, 1.8763e-02, 1.5910e-02,\n",
      "        1.4366e-02, 1.1990e-02, 1.1217e-02, 9.2042e-03, 8.1674e-03, 7.0435e-03,\n",
      "        5.8103e-03, 5.4599e-03, 4.9591e-03, 4.1334e-03, 3.7706e-03, 3.5436e-03,\n",
      "        3.4935e-03, 2.9799e-03, 2.5745e-03, 2.3124e-03, 2.1558e-03, 1.9460e-03,\n",
      "        1.7900e-03, 1.5160e-03, 1.4561e-03, 1.2781e-03, 1.2929e-03, 1.1849e-03,\n",
      "        1.0644e-03, 1.0119e-03, 9.6046e-04, 9.1256e-04, 8.7110e-04, 8.3233e-04])\n",
      "tensor([2.2891e+00, 1.5745e+00, 5.7168e-01, 3.9487e-01, 3.1370e-01, 2.5702e-01,\n",
      "        2.1255e-01, 1.7929e-01, 1.5466e-01, 1.3422e-01, 1.2005e-01, 1.0548e-01,\n",
      "        9.3844e-02, 8.3965e-02, 7.6405e-02, 6.7771e-02, 6.0910e-02, 5.4658e-02,\n",
      "        4.8699e-02, 4.4548e-02, 3.9747e-02, 3.4967e-02, 3.2041e-02, 2.8196e-02,\n",
      "        2.5150e-02, 2.1892e-02, 1.9957e-02, 1.7437e-02, 1.5076e-02, 1.3314e-02,\n",
      "        1.1312e-02, 1.0308e-02, 8.7325e-03, 7.9995e-03, 6.5388e-03, 5.9163e-03,\n",
      "        5.0650e-03, 4.4388e-03, 4.1216e-03, 3.6711e-03, 3.1276e-03, 2.8816e-03,\n",
      "        2.5252e-03, 2.4512e-03, 2.1091e-03, 2.0374e-03, 1.6846e-03, 1.6000e-03,\n",
      "        1.4817e-03, 1.3895e-03, 1.2400e-03, 1.1625e-03, 1.1352e-03, 1.0546e-03,\n",
      "        9.9583e-04, 9.4470e-04, 9.0377e-04, 8.5605e-04, 8.1537e-04, 8.1596e-04])\n"
     ]
    }
   ],
   "source": [
    "testacc = np.zeros((3,5))\n",
    "losses_exp = np.zeros((3,5))\n",
    "for layer in range(1,4):\n",
    "    for units in range(50,251,50):\n",
    "\n",
    "       t,l = function2trainTheModel(units=units,layers=layer)\n",
    "       col = units//50-1\n",
    "       testacc[layer-1,col] = np.mean(t)\n",
    "       print(l)\n",
    "       losses_exp[layer-1,col] = torch.mean(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[95.44961548 95.7285614  96.1361084  96.1007843  96.19087982]\n",
      " [94.99523926 95.63967896 95.86626434 96.03134155 96.27976227]\n",
      " [93.11230469 94.5103302  94.65079498 94.96705627 95.30435944]]\n"
     ]
    }
   ],
   "source": [
    "print(testacc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
